{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7984acbf-dc16-489e-89ca-b5e2a0b00ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.48.3 in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.3) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.3) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (2024.8.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install transformers=='4.48.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06cc1cfc-202e-470c-b3e5-761f7d01dd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beir==2.0.0 in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (from beir==2.0.0) (3.4.1)\n",
      "Requirement already satisfied: pytrec-eval in /usr/local/lib/python3.11/dist-packages (from beir==2.0.0) (0.5)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (from beir==2.0.0) (1.10.0)\n",
      "Requirement already satisfied: elasticsearch==7.9.1 in /usr/local/lib/python3.11/dist-packages (from beir==2.0.0) (7.9.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from beir==2.0.0) (3.4.1)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from elasticsearch==7.9.1->beir==2.0.0) (2.2.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from elasticsearch==7.9.1->beir==2.0.0) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->beir==2.0.0) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (3.11.14)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (0.29.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->beir==2.0.0) (6.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->beir==2.0.0) (4.48.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->beir==2.0.0) (2.4.1+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->beir==2.0.0) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->beir==2.0.0) (1.15.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->beir==2.0.0) (10.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->beir==2.0.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->beir==2.0.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->beir==2.0.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->beir==2.0.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->beir==2.0.0) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->beir==2.0.0) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->beir==2.0.0) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets->beir==2.0.0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->beir==2.0.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->beir==2.0.0) (3.10)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->beir==2.0.0) (3.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->beir==2.0.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->beir==2.0.0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->beir==2.0.0) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->beir==2.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->beir==2.0.0) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->beir==2.0.0) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers->beir==2.0.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers->beir==2.0.0) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->beir==2.0.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers->beir==2.0.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.11.0->sentence-transformers->beir==2.0.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install beir=='2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95990c38-fb32-4d11-a65f-94c511b2b7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 19 09:14:17 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.77                 Driver Version: 565.77         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A5000               On  |   00000000:03:00.0 Off |                  Off |\n",
      "|  0%   24C    P8             26W /  230W |       2MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2deb81c0-e85e-4e01-ae15-50787e26f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import logging\n",
    "from datetime import timedelta\n",
    "from typing import List, Dict, Union, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.distributed as dist\n",
    "from tqdm import trange\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers.file_utils import PaddingStrategy\n",
    "\n",
    "from beir import util, LoggingHandler\n",
    "from beir.retrieval import models\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def last_token_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "    batch_size = last_hidden.shape[0]\n",
    "    embedding = last_hidden[torch.arange(batch_size, device=last_hidden.device), sequence_lengths]\n",
    "    return embedding\n",
    "\n",
    "# The prompt for queries\n",
    "def get_detailed_instruct_query(task_description: str, query: str) -> str:\n",
    "    return f'{task_description}\\nQuery: {query}'\n",
    "\n",
    "# The prompt for passages\n",
    "def get_detailed_instruct_passage(passage: str) -> str:\n",
    "    return f'Represent this passage\\npassage: {passage}'\n",
    "\n",
    "class SentenceBERT:\n",
    "    def __init__(self, model_path: Union[str, Tuple] = \"BMRetriever/BMRetriever-410M\", sep: str = \" \", dataset=\"nfcorpus\", **kwargs):\n",
    "        self.sep = sep\n",
    "        self.tasks = {\n",
    "                        'nfcorpus': 'Given a question, retrieve relevant documents that best answer the question',\n",
    "                        'scifact': 'Given a scientific claim, retrieve documents that support or refute the claim',\n",
    "                        'trec-covid': 'Given a query on COVID-19, retrieve documents that answer the query',\n",
    "                     }\n",
    "        self.task = self.tasks[dataset]\n",
    "        self.dataset = dataset\n",
    "        self.model_path = model_path\n",
    "        self.model = AutoModel.from_pretrained(model_path, torch_dtype=torch.float32).cuda()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.max_length = 512\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            self.tokenizer.padding_side = \"left\"\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def encode(self, input_texts: List[str], batch_size: int = 32, **kwargs) -> Tensor:\n",
    "        embeddings = []\n",
    "        self.model.eval()\n",
    "        for i in trange(0, len(input_texts), batch_size):\n",
    "            input_text = input_texts[i: (i+batch_size)]\n",
    "            batch_dict = self.tokenizer(\n",
    "                input_text,\n",
    "                max_length=self.max_length-1,\n",
    "                return_attention_mask=False,\n",
    "                return_token_type_ids=False,\n",
    "                padding=PaddingStrategy.DO_NOT_PAD,\n",
    "                truncation=True\n",
    "            )\n",
    "            with torch.cuda.amp.autocast():\n",
    "                batch_dict['input_ids'] = [input_ids + [self.tokenizer.eos_token_id] for input_ids in batch_dict['input_ids']]\n",
    "                batch_dict = self.tokenizer.pad(batch_dict, padding=True, return_attention_mask=True, return_tensors='pt').to(\"cuda\")\n",
    "                outputs = self.model(**batch_dict)\n",
    "                embedding = last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "                embeddings.append(embedding)\n",
    "        embeddings = torch.cat(embeddings, dim=0)\n",
    "        logger.info(f\"Embeddings shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "    def encode_queries(self, queries: List[str], batch_size: int = 32, **kwargs) -> Tensor:\n",
    "        queries = [get_detailed_instruct_query(self.task, query) for query in queries]\n",
    "        embeddings = self.encode(queries, batch_size=batch_size, **kwargs)\n",
    "        return embeddings\n",
    "\n",
    "    def encode_corpus(self, corpus: Union[List[Dict[str, str]], Dict[str, List]], batch_size: int = 32, **kwargs) -> Tensor:\n",
    "        if isinstance(corpus, dict):\n",
    "            sentences = [(corpus[\"title\"][i] + self.sep + corpus[\"text\"][i]).strip() if \"title\" in corpus else corpus[\"text\"][i].strip() for i in range(len(corpus['text']))]\n",
    "        else:\n",
    "            sentences = [(doc[\"title\"] + self.sep + doc[\"text\"]).strip() if \"title\" in doc else doc[\"text\"].strip() for doc in corpus]\n",
    "        sentences = [get_detailed_instruct_passage(passage) for passage in sentences]\n",
    "        embeddings = self.encode(sentences, batch_size=batch_size, **kwargs)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d31ea6-5497-47c5-b7d1-5684029d6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_ret = DRES(SentenceBERT(model_path=\"BMRetriever/BMRetriever-410M\"), dataset = 'nfcorpus', batch_size=32)\n",
    "retriever_bm_ret = EvaluateRetrieval(bm_ret, score_function=\"dot\") # or \"cos_sim\" for cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d5b2ed-bcc1-4c0c-a318-ed4c81fc865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load dataset\n",
    "dataset = \"nfcorpus\" # dataset name\n",
    "url = f\"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{dataset}.zip\"\n",
    "out_dir = \"datasets\"\n",
    "data_path = util.download_and_unzip(url, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f1f4f9-d38d-42da-8233-a279e0b7555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:14:55 - Loading Corpus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0510445ef5814dd981f6737932e5ef5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:14:55 - Loaded 3633 TEST Documents.\n",
      "2025-03-19 09:14:55 - Doc Example: {'text': 'Recent studies have suggested that statins, an established drug group in the prevention of cardiovascular mortality, could delay or prevent breast cancer recurrence but the effect on disease-specific mortality remains unclear. We evaluated risk of breast cancer death among statin users in a population-based cohort of breast cancer patients. The study cohort included all newly diagnosed breast cancer patients in Finland during 1995–2003 (31,236 cases), identified from the Finnish Cancer Registry. Information on statin use before and after the diagnosis was obtained from a national prescription database. We used the Cox proportional hazards regression method to estimate mortality among statin users with statin use as time-dependent variable. A total of 4,151 participants had used statins. During the median follow-up of 3.25 years after the diagnosis (range 0.08–9.0 years) 6,011 participants died, of which 3,619 (60.2%) was due to breast cancer. After adjustment for age, tumor characteristics, and treatment selection, both post-diagnostic and pre-diagnostic statin use were associated with lowered risk of breast cancer death (HR 0.46, 95% CI 0.38–0.55 and HR 0.54, 95% CI 0.44–0.67, respectively). The risk decrease by post-diagnostic statin use was likely affected by healthy adherer bias; that is, the greater likelihood of dying cancer patients to discontinue statin use as the association was not clearly dose-dependent and observed already at low-dose/short-term use. The dose- and time-dependence of the survival benefit among pre-diagnostic statin users suggests a possible causal effect that should be evaluated further in a clinical trial testing statins’ effect on survival in breast cancer patients.', 'title': 'Statin Use and Breast Cancer Survival: A Nationwide Cohort Study from Finland'}\n",
      "2025-03-19 09:14:55 - Loading Queries...\n",
      "2025-03-19 09:14:56 - Loaded 323 TEST Queries.\n",
      "2025-03-19 09:14:56 - Query Example: Do Cholesterol Statin Drugs Cause Breast Cancer?\n"
     ]
    }
   ],
   "source": [
    "# Load corpus, queries, and qrels\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f3ab9b9-207e-4a22-a57a-bf2d408ac385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# load paraphrased dataset\n",
    "with open(f\"{dataset}_query_paraphrased_gpt4o.json\", encoding='utf-8') as f:\n",
    "    # Load the JSON data into a Python dictionary\n",
    "    queries_para = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6727054-0466-4d27-a707-c5d62a4efc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_p = {}\n",
    "for q in queries_para:\n",
    "  queries_p[q] = queries_para[q]['query_p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "654132ec-3afc-42f0-ae7c-4a83c73bd9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:15:00 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]/tmp/ipykernel_1542/3345242825.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 11/11 [00:01<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:15:01 - Embeddings shape: torch.Size([323, 1024])\n",
      "2025-03-19 09:15:01 - Sorting Corpus by document length (Longest first)...\n",
      "2025-03-19 09:15:01 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2025-03-19 09:15:01 - Scoring Function: Dot Product (dot)\n",
      "2025-03-19 09:15:01 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:20<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:15:21 - Embeddings shape: torch.Size([3633, 1024])\n"
     ]
    }
   ],
   "source": [
    "results_bm_ret = retriever_bm_ret.retrieve(corpus, queries_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce66097e-f455-4bbe-acd6-e874a5c0e5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:17:15 - For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-03-19 09:17:15 - \n",
      "\n",
      "2025-03-19 09:17:15 - NDCG@1: 0.3158\n",
      "2025-03-19 09:17:15 - NDCG@3: 0.2855\n",
      "2025-03-19 09:17:15 - NDCG@5: 0.2654\n",
      "2025-03-19 09:17:15 - NDCG@10: 0.2447\n",
      "2025-03-19 09:17:15 - NDCG@100: 0.2385\n",
      "2025-03-19 09:17:15 - NDCG@1000: 0.3341\n",
      "2025-03-19 09:17:15 - \n",
      "\n",
      "2025-03-19 09:17:15 - MAP@1: 0.0384\n",
      "2025-03-19 09:17:15 - MAP@3: 0.0595\n",
      "2025-03-19 09:17:15 - MAP@5: 0.0705\n",
      "2025-03-19 09:17:15 - MAP@10: 0.0833\n",
      "2025-03-19 09:17:15 - MAP@100: 0.1071\n",
      "2025-03-19 09:17:15 - MAP@1000: 0.1195\n",
      "2025-03-19 09:17:15 - \n",
      "\n",
      "2025-03-19 09:17:15 - Recall@1: 0.0384\n",
      "2025-03-19 09:17:15 - Recall@3: 0.0690\n",
      "2025-03-19 09:17:15 - Recall@5: 0.0867\n",
      "2025-03-19 09:17:15 - Recall@10: 0.1194\n",
      "2025-03-19 09:17:15 - Recall@100: 0.2609\n",
      "2025-03-19 09:17:15 - Recall@1000: 0.5879\n",
      "2025-03-19 09:17:15 - \n",
      "\n",
      "2025-03-19 09:17:15 - P@1: 0.3313\n",
      "2025-03-19 09:17:15 - P@3: 0.2693\n",
      "2025-03-19 09:17:15 - P@5: 0.2297\n",
      "2025-03-19 09:17:15 - P@10: 0.1842\n",
      "2025-03-19 09:17:15 - P@100: 0.0629\n",
      "2025-03-19 09:17:15 - P@1000: 0.0195\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model with NDCG@k, MAP@K, Recall@K and Precision@K where k = [1,3,5,10,100,1000]\n",
    "ndcg, _map, recall, precision = retriever_bm_ret.evaluate(qrels, results_bm_ret, retriever_bm_ret.k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "574ac1ea-1fa9-4553-bef0-589e4606c04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BMRet; Dataset: nfcorpus (paraphrased)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "{'NDCG@1': 0.31579, 'NDCG@3': 0.28547, 'NDCG@5': 0.26537, 'NDCG@10': 0.24469, 'NDCG@100': 0.23854, 'NDCG@1000': 0.33409}\n",
      "{'MAP@1': 0.03845, 'MAP@3': 0.0595, 'MAP@5': 0.07052, 'MAP@10': 0.08325, 'MAP@100': 0.10706, 'MAP@1000': 0.11951}\n",
      "{'Recall@1': 0.03845, 'Recall@3': 0.06901, 'Recall@5': 0.08669, 'Recall@10': 0.11941, 'Recall@100': 0.26092, 'Recall@1000': 0.5879}\n",
      "{'P@1': 0.33127, 'P@3': 0.26935, 'P@5': 0.22972, 'P@10': 0.18421, 'P@100': 0.06288, 'P@1000': 0.0195}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model: BMRet; Dataset: {dataset} (paraphrased)\")\n",
    "print(\"-\" * 150)\n",
    "print(ndcg)\n",
    "print(_map)\n",
    "print(recall)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4d27c00-a490-4cd8-9d41-ccc497b9948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_ret = DRES(SentenceBERT(model_path=\"BMRetriever/BMRetriever-410M\"), dataset = 'scifact', batch_size=32)\n",
    "retriever_bm_ret = EvaluateRetrieval(bm_ret, score_function=\"dot\") # or \"cos_sim\" for cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5de97b6-e5c8-4c76-8453-3cc94e040d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:18:37 - Downloading scifact.zip ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50dcc9dbf40472b92d97018abee5463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "datasets/scifact.zip:   0%|          | 0.00/2.69M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:18:37 - Unzipping scifact.zip ...\n"
     ]
    }
   ],
   "source": [
    "# Download and load dataset\n",
    "dataset = \"scifact\" # dataset name\n",
    "url = f\"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{dataset}.zip\"\n",
    "out_dir = \"datasets\"\n",
    "data_path = util.download_and_unzip(url, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bf787d3-21c7-4c03-af0c-04ce436d302b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:18:50 - Loading Corpus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66f19bad3114216a5c96bcc87ef98ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:18:51 - Loaded 5183 TEST Documents.\n",
      "2025-03-19 09:18:51 - Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}\n",
      "2025-03-19 09:18:51 - Loading Queries...\n",
      "2025-03-19 09:18:51 - Loaded 300 TEST Queries.\n",
      "2025-03-19 09:18:51 - Query Example: 0-dimensional biomaterials show inductive properties.\n"
     ]
    }
   ],
   "source": [
    "# Load corpus, queries, and qrels\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57be5738-fa61-4792-8764-382590e1d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# load paraphrased dataset\n",
    "with open(f\"{dataset}_query_paraphrased_gpt4o.json\", encoding='utf-8') as f:\n",
    "    # Load the JSON data into a Python dictionary\n",
    "    queries_para = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25d122a5-c492-4c37-8125-bb99cceb4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_p = {}\n",
    "for q in queries_para:\n",
    "  queries_p[q] = queries_para[q]['query_p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95c2b253-33e9-4bef-830f-7eaf043247d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:19:33 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/tmp/ipykernel_1542/3345242825.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 10/10 [00:00<00:00, 31.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:19:34 - Embeddings shape: torch.Size([300, 1024])\n",
      "2025-03-19 09:19:34 - Sorting Corpus by document length (Longest first)...\n",
      "2025-03-19 09:19:34 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2025-03-19 09:19:34 - Scoring Function: Dot Product (dot)\n",
      "2025-03-19 09:19:34 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:26<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:20:00 - Embeddings shape: torch.Size([5183, 1024])\n"
     ]
    }
   ],
   "source": [
    "results_bm_ret = retriever_bm_ret.retrieve(corpus, queries_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed2bbd45-f511-4ef8-b6e1-4d4a08dc4dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:20:53 - For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-03-19 09:20:53 - \n",
      "\n",
      "2025-03-19 09:20:53 - NDCG@1: 0.5667\n",
      "2025-03-19 09:20:53 - NDCG@3: 0.6285\n",
      "2025-03-19 09:20:53 - NDCG@5: 0.6537\n",
      "2025-03-19 09:20:53 - NDCG@10: 0.6770\n",
      "2025-03-19 09:20:53 - NDCG@100: 0.7082\n",
      "2025-03-19 09:20:53 - NDCG@1000: 0.7159\n",
      "2025-03-19 09:20:53 - \n",
      "\n",
      "2025-03-19 09:20:53 - MAP@1: 0.5403\n",
      "2025-03-19 09:20:53 - MAP@3: 0.6029\n",
      "2025-03-19 09:20:53 - MAP@5: 0.6210\n",
      "2025-03-19 09:20:53 - MAP@10: 0.6322\n",
      "2025-03-19 09:20:53 - MAP@100: 0.6405\n",
      "2025-03-19 09:20:53 - MAP@1000: 0.6407\n",
      "2025-03-19 09:20:53 - \n",
      "\n",
      "2025-03-19 09:20:53 - Recall@1: 0.5403\n",
      "2025-03-19 09:20:53 - Recall@3: 0.6726\n",
      "2025-03-19 09:20:53 - Recall@5: 0.7350\n",
      "2025-03-19 09:20:53 - Recall@10: 0.8012\n",
      "2025-03-19 09:20:53 - Recall@100: 0.9333\n",
      "2025-03-19 09:20:53 - Recall@1000: 0.9967\n",
      "2025-03-19 09:20:53 - \n",
      "\n",
      "2025-03-19 09:20:53 - P@1: 0.5667\n",
      "2025-03-19 09:20:53 - P@3: 0.2456\n",
      "2025-03-19 09:20:53 - P@5: 0.1640\n",
      "2025-03-19 09:20:53 - P@10: 0.0907\n",
      "2025-03-19 09:20:53 - P@100: 0.0106\n",
      "2025-03-19 09:20:53 - P@1000: 0.0011\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model with NDCG@k, MAP@K, Recall@K and Precision@K where k = [1,3,5,10,100,1000]\n",
    "ndcg, _map, recall, precision = retriever_bm_ret.evaluate(qrels, results_bm_ret, retriever_bm_ret.k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb8a0a3e-52b6-4d2f-a10d-6d68e3f24e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BMRet; Dataset: scifact (paraphrased)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "{'NDCG@1': 0.56667, 'NDCG@3': 0.62847, 'NDCG@5': 0.65373, 'NDCG@10': 0.67702, 'NDCG@100': 0.70823, 'NDCG@1000': 0.7159}\n",
      "{'MAP@1': 0.54028, 'MAP@3': 0.60287, 'MAP@5': 0.62103, 'MAP@10': 0.6322, 'MAP@100': 0.64049, 'MAP@1000': 0.64072}\n",
      "{'Recall@1': 0.54028, 'Recall@3': 0.67256, 'Recall@5': 0.735, 'Recall@10': 0.80122, 'Recall@100': 0.93333, 'Recall@1000': 0.99667}\n",
      "{'P@1': 0.56667, 'P@3': 0.24556, 'P@5': 0.164, 'P@10': 0.09067, 'P@100': 0.01063, 'P@1000': 0.00113}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model: BMRet; Dataset: {dataset} (paraphrased)\")\n",
    "print(\"-\" * 150)\n",
    "print(ndcg)\n",
    "print(_map)\n",
    "print(recall)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bfe4beb-fbbe-4983-bc7f-6a85a6e183ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_ret = DRES(SentenceBERT(model_path=\"BMRetriever/BMRetriever-410M\"), dataset = 'trec-covid', batch_size=32)\n",
    "retriever_bm_ret = EvaluateRetrieval(bm_ret, score_function=\"dot\") # or \"cos_sim\" for cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ce47712-eac7-46ff-9ae9-a76740d26c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:23:05 - Downloading trec-covid.zip ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ea28b962fd409ba51d54f3f8b2bab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "datasets/trec-covid.zip:   0%|          | 0.00/70.5M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:23:12 - Unzipping trec-covid.zip ...\n"
     ]
    }
   ],
   "source": [
    "# Download and load dataset\n",
    "dataset = \"trec-covid\" # dataset name\n",
    "url = f\"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{dataset}.zip\"\n",
    "out_dir = \"datasets\"\n",
    "data_path = util.download_and_unzip(url, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2c81314-b0be-4cea-be88-03b1c358bfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:23:48 - Loading Corpus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3a496a492f4c1d8a4dff1480063e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/171332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:23:50 - Loaded 171332 TEST Documents.\n",
      "2025-03-19 09:23:50 - Doc Example: {'text': 'OBJECTIVE: This retrospective chart review describes the epidemiology and clinical features of 40 patients with culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia. METHODS: Patients with positive M. pneumoniae cultures from respiratory specimens from January 1997 through December 1998 were identified through the Microbiology records. Charts of patients were reviewed. RESULTS: 40 patients were identified, 33 (82.5%) of whom required admission. Most infections (92.5%) were community-acquired. The infection affected all age groups but was most common in infants (32.5%) and pre-school children (22.5%). It occurred year-round but was most common in the fall (35%) and spring (30%). More than three-quarters of patients (77.5%) had comorbidities. Twenty-four isolates (60%) were associated with pneumonia, 14 (35%) with upper respiratory tract infections, and 2 (5%) with bronchiolitis. Cough (82.5%), fever (75%), and malaise (58.8%) were the most common symptoms, and crepitations (60%), and wheezes (40%) were the most common signs. Most patients with pneumonia had crepitations (79.2%) but only 25% had bronchial breathing. Immunocompromised patients were more likely than non-immunocompromised patients to present with pneumonia (8/9 versus 16/31, P = 0.05). Of the 24 patients with pneumonia, 14 (58.3%) had uneventful recovery, 4 (16.7%) recovered following some complications, 3 (12.5%) died because of M pneumoniae infection, and 3 (12.5%) died due to underlying comorbidities. The 3 patients who died of M pneumoniae pneumonia had other comorbidities. CONCLUSION: our results were similar to published data except for the finding that infections were more common in infants and preschool children and that the mortality rate of pneumonia in patients with comorbidities was high.', 'title': 'Clinical features of culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia'}\n",
      "2025-03-19 09:23:50 - Loading Queries...\n",
      "2025-03-19 09:23:50 - Loaded 50 TEST Queries.\n",
      "2025-03-19 09:23:50 - Query Example: what is the origin of COVID-19\n"
     ]
    }
   ],
   "source": [
    "# Load corpus, queries, and qrels\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f7f2719-a29f-432e-9294-a80c2bcdda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# load paraphrased dataset\n",
    "with open(f\"{dataset}_query_paraphrased_gpt4o.json\", encoding='utf-8') as f:\n",
    "    # Load the JSON data into a Python dictionary\n",
    "    queries_para = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3154461-8b22-4853-823b-fc7312565a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_p = {}\n",
    "for q in queries_para:\n",
    "  queries_p[q] = queries_para[q]['query_p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "111b860f-2c29-4d0f-8b61-52e7473e1740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:24:27 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/tmp/ipykernel_1542/3345242825.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 2/2 [00:00<00:00, 19.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:24:27 - Embeddings shape: torch.Size([50, 1024])\n",
      "2025-03-19 09:24:27 - Sorting Corpus by document length (Longest first)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:24:28 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2025-03-19 09:24:28 - Scoring Function: Dot Product (dot)\n",
      "2025-03-19 09:24:28 - Encoding Batch 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [05:50<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:30:19 - Embeddings shape: torch.Size([50000, 1024])\n",
      "2025-03-19 09:30:19 - Encoding Batch 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [04:06<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:34:25 - Embeddings shape: torch.Size([50000, 1024])\n",
      "2025-03-19 09:34:25 - Encoding Batch 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:43<00:00, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:36:09 - Embeddings shape: torch.Size([50000, 1024])\n",
      "2025-03-19 09:36:09 - Encoding Batch 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 667/667 [00:14<00:00, 44.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:36:24 - Embeddings shape: torch.Size([21332, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_bm_ret = retriever_bm_ret.retrieve(corpus, queries_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e1322fb-5941-4b1f-9722-1d3653510c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 09:37:33 - For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-03-19 09:37:33 - \n",
      "\n",
      "2025-03-19 09:37:33 - NDCG@1: 0.5900\n",
      "2025-03-19 09:37:33 - NDCG@3: 0.6253\n",
      "2025-03-19 09:37:33 - NDCG@5: 0.6225\n",
      "2025-03-19 09:37:33 - NDCG@10: 0.6062\n",
      "2025-03-19 09:37:33 - NDCG@100: 0.4617\n",
      "2025-03-19 09:37:33 - NDCG@1000: 0.4179\n",
      "2025-03-19 09:37:33 - \n",
      "\n",
      "2025-03-19 09:37:33 - MAP@1: 0.0018\n",
      "2025-03-19 09:37:33 - MAP@3: 0.0055\n",
      "2025-03-19 09:37:33 - MAP@5: 0.0087\n",
      "2025-03-19 09:37:33 - MAP@10: 0.0162\n",
      "2025-03-19 09:37:33 - MAP@100: 0.0864\n",
      "2025-03-19 09:37:33 - MAP@1000: 0.1984\n",
      "2025-03-19 09:37:33 - \n",
      "\n",
      "2025-03-19 09:37:33 - Recall@1: 0.0018\n",
      "2025-03-19 09:37:33 - Recall@3: 0.0058\n",
      "2025-03-19 09:37:33 - Recall@5: 0.0096\n",
      "2025-03-19 09:37:33 - Recall@10: 0.0185\n",
      "2025-03-19 09:37:33 - Recall@100: 0.1175\n",
      "2025-03-19 09:37:33 - Recall@1000: 0.3922\n",
      "2025-03-19 09:37:33 - \n",
      "\n",
      "2025-03-19 09:37:33 - P@1: 0.6400\n",
      "2025-03-19 09:37:33 - P@3: 0.7000\n",
      "2025-03-19 09:37:33 - P@5: 0.6920\n",
      "2025-03-19 09:37:33 - P@10: 0.6600\n",
      "2025-03-19 09:37:33 - P@100: 0.4774\n",
      "2025-03-19 09:37:33 - P@1000: 0.1821\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model with NDCG@k, MAP@K, Recall@K and Precision@K where k = [1,3,5,10,100,1000]\n",
    "ndcg, _map, recall, precision = retriever_bm_ret.evaluate(qrels, results_bm_ret, retriever_bm_ret.k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76f1d8cf-b007-4108-8fed-9e1819d4515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BMRet; Dataset: trec-covid (paraphrased)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "{'NDCG@1': 0.59, 'NDCG@3': 0.62531, 'NDCG@5': 0.62252, 'NDCG@10': 0.60625, 'NDCG@100': 0.46169, 'NDCG@1000': 0.41788}\n",
      "{'MAP@1': 0.00184, 'MAP@3': 0.00548, 'MAP@5': 0.00872, 'MAP@10': 0.01615, 'MAP@100': 0.08639, 'MAP@1000': 0.19845}\n",
      "{'Recall@1': 0.00184, 'Recall@3': 0.00582, 'Recall@5': 0.00964, 'Recall@10': 0.01848, 'Recall@100': 0.11753, 'Recall@1000': 0.39218}\n",
      "{'P@1': 0.64, 'P@3': 0.7, 'P@5': 0.692, 'P@10': 0.66, 'P@100': 0.4774, 'P@1000': 0.18214}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model: BMRet; Dataset: {dataset} (paraphrased)\")\n",
    "print(\"-\" * 150)\n",
    "print(ndcg)\n",
    "print(_map)\n",
    "print(recall)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdd8375-7175-40d1-8b36-dc173b18bdad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
